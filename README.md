Devcontainer setup for NVIDIA Reinforcement Learning Fine-Tuning tutorial. 

For this [blog post](https://blogs.nvidia.com/blog/rtx-ai-garage-fine-tuning-unsloth-dgx-spark/), which linked to this [Youtube video](https://www.youtube.com/watch?v=9t-BAjzBWj8), which links to [this notebook](https://colab.research.google.com/github/openai/gpt-oss/blob/main/examples/reinforcement-fine-tuning.ipynb#scrollTo=CGoDZwcunHEU).

I didn't want to set up CUDA on my dev machine, considering the various combinations of CUDA, PyTorch and driver versions often involved. It was simpler to just set up this environment for easier reuse and isolation. 

